{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691325a8-4307-4e7f-a00c-4ea3a6e0180a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7ffdd75edcd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from IPython.display import clear_output\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Enable interactive mode\n",
    "plt.ion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3cd2a5-d8f7-4df4-962d-7018c536d734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/scratch/project_2006600/fin_experiment/372080994826105752', creation_time=1734112413085, experiment_id='372080994826105752', last_update_time=1734112413085, lifecycle_stage='active', name='fin_experiment', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "# set the experiment id\n",
    "mlflow.set_tracking_uri(\"/scratch/project_2006600/fin_experiment_cnn\")\n",
    "mlflow.set_experiment('fin_experiment_cnn')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f5831b-8ccf-4d56-aff2-c2eeead5db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    clear_output(wait=True)  # Clear previous output in Jupyter\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('N Batches')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6af7534-8ca6-4f1c-911a-1d7ec3a0f9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def load_glove_embeddings(filepath):\n",
    "    embeddings = {}\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "# Load GloVe embeddings\n",
    "glove_path = \"/projappl/project_2006600/fin_experiment/embeddings/glove.6B.100d.txt\"\n",
    "glove_embeddings = load_glove_embeddings(glove_path)\n",
    "print(f\"Loaded {len(glove_embeddings)} word vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f157053a-11b6-488a-9b23-c3ae68a3d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/projappl/project_2006600/fin_experiment/data'\n",
    "data_combined_news = pd.read_csv(os.path.join(data_dir, 'data_combined_news.csv'), sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f7a64b0-31c8-48bf-a0f9-d786af90523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data_combined_news['All_news_clean']\n",
    "y = data_combined_news['Label']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19329193-8ade-45e9-932e-cb07ebb6929f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1591"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3c1be32-40dd-467f-8ff0-abd7c9222378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    838\n",
       "0    753\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c020c5c-2839-4e0b-9481-dc24c4ac7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \"\"\"Vocabulary for text.\"\"\"\n",
    "    def __init__(self, texts, min_freq=5, reserved_tokens=[]):\n",
    "        counter = dict()\n",
    "        for text in texts:\n",
    "            for word in text.split():\n",
    "                counter[word] = counter.get(word, 0) + 1\n",
    "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                  reverse=True)\n",
    "        # The list of unique tokens\n",
    "        self.idx_to_token = list(sorted(set(['<unk>'] + reserved_tokens + [\n",
    "            token for token, freq in self.token_freqs if freq >= min_freq])))\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def get(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if hasattr(indices, '__len__') and len(indices) > 1:\n",
    "            return [self.idx_to_token[int(index)] for index in indices]\n",
    "        return self.idx_to_token[indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # Index for the unknown token\n",
    "        return self.token_to_idx['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a5b47db-e92c-4280-8411-ca4a91e55688",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(data_combined_news['All_news_clean'])\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a681da-3b79-49c4-88ab-ca85543482c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "506f949b-7ae3-40b3-a5f1-633c46d9dcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    227\n",
       "0    171\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc687ad1-e151-4b36-b3fe-9ba6745132e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ontario is putting an end to coal-burning power plants      on the verge of becoming the first industrial region in north america to eliminate all coal-fired electrical generation   in sign of growing chinese frustration with north korea  daily show clip mocking kim jong un gets 2 8 million views on china web portal  making it the 2nd most viewed daily show segment ever north korea to  launch missile tomorrow  after warning foreigners to evacuate south   world   news french intelligence agency forces wikipedia volunteer to delete article  re-instated  it becomes most-read page on french wikipedia jewish terrorist who murdered two palestinians gets 2 life sentences in israeli jail 10-year-old rape victim put behind bars- times of india  ding dong  the witch is dead  set to enter uk official top 40 following margaret thatcher s death street parties break out in london and across the uk over death of margaret thatcher now hiring  fake somali pirates  foreign journalists have paid kenyans pretending to be somali pirates hundreds of dollars to interview them  japan deploys three patriot missile defense batteries in tokyo  a chain of pac-3 batteries to okinawa  and aegis missile defense destroyers to the sea of japan the british are watering our whiskey  warned american diplomat in 1973  via wikileaks  us tear gas shipment -140 000 canisters - arrives in egypt  while in syria  frontline filmmaker olly lambert did not anticipate that bombs from government jets would begin to fall just 300 meters away   warning  graphic violence  south korean politician  we need tactical nukes to send message to china how a single spy turned pakistan against the united states  what really happened after raymond davis killed two men in the street in lahore  north korea workers don t report for work at joint industrial park japanese woman with megaphone in osaka   i hate koreans so much    we will start tsuruhashi massacre like nanking massacre   crowd cheers  afghanistan mineral deposits estimated at  1 trillion the pirate bay moves to  gl domain in anticipation of domain seizure  the pirate bay has received indications that the swedish authorities might soon attempt to seize the sites  se domain margaret thatcher was freakishly correct about why the euro would be such a big disaster us navy deploying laser weapon prototype in persian gulf the sun reports that kim jong un starred in a grease production while going to school in switzerland putin says russia does not discriminate against gays north korea  ex-soldiers recall  golden days  of military drills   world news france wants to keep 1 000 soldiers in mali permanently ontario is putting an end to coal-burning power plants      on the verge of becoming the first industrial region in north america to eliminate all coal-fired electrical generation   in sign of growing chinese frustration with north korea  daily show clip mocking kim jong un gets 2 8 million views on china web portal  making it the 2nd most viewed daily show segment ever north korea to  launch missile tomorrow  after warning foreigners to evacuate south   world   news french intelligence agency forces wikipedia volunteer to delete article  re-instated  it becomes most-read page on french wikipedia jewish terrorist who murdered two palestinians gets 2 life sentences in israeli jail 10-year-old rape victim put behind bars- times of india  ding dong  the witch is dead  set to enter uk official top 40 following margaret thatcher s death street parties break out in london and across the uk over death of margaret thatcher now hiring  fake somali pirates  foreign journalists have paid kenyans pretending to be somali pirates hundreds of dollars to interview them  japan deploys three patriot missile defense batteries in tokyo  a chain of pac-3 batteries to okinawa  and aegis missile defense destroyers to the sea of japan the british are watering our whiskey  warned american diplomat in 1973  via wikileaks  us tear gas shipment -140 000 canisters - arrives in egypt  while in syria  frontline filmmaker olly lambert did not anticipate that bombs from government jets would begin to fall just 300 meters away   warning  graphic violence  south korean politician  we need tactical nukes to send message to china how a single spy turned pakistan against the united states  what really happened after raymond davis killed two men in the street in lahore  north korea workers don t report for work at joint industrial park japanese woman with megaphone in osaka   i hate koreans so much    we will start tsuruhashi massacre like nanking massacre   crowd cheers  afghanistan mineral deposits estimated at  1 trillion the pirate bay moves to  gl domain in anticipation of domain seizure  the pirate bay has received indications that the swedish authorities might soon attempt to seize the sites  se domain margaret thatcher was freakishly correct about why the euro would be such a big disaster us navy deploying laser weapon prototype in persian gulf the sun reports that kim jong un starred in a grease production while going to school in switzerland putin says russia does not discriminate against gays north korea  ex-soldiers recall  golden days  of military drills   world news france wants to keep 1 000 soldiers in mali permanently'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[1173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f0b97c6-c8fb-4817-a608-20f8c28928a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize \n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "# Below we use indexes of tokens in a vocab dict, without any segmentation of tokens, because we use count-based approaches\n",
    "# or pre-trained word embeddings like glove/word2vec\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "def nltk_tokenize(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return [word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenize(text)\n",
    "\n",
    "def build_vocab(texts):\n",
    "    counter = dict()\n",
    "    for text in texts:\n",
    "        for word in text.split():\n",
    "            counter[word] = counter.get(word, 0) + 1\n",
    "    vocab = {token: idx + 1 for idx, token in enumerate(counter.keys())}\n",
    "    vocab['<unk>'] = 0\n",
    "    vocab['<pad>'] = len(vocab)\n",
    "    print(f'Vocab length: {len(vocab)}')\n",
    "    return vocab\n",
    "\n",
    "def encode_texts(texts, vocab):\n",
    "    return [torch.tensor([vocab.get(token, 0) for token in tokenize(text)]) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aa02fa1-2f18-48e5-ae37-65a7cbe0945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1999995 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def load_fasttext_embeddings(filepath, embedding_dim):\n",
    "    embeddings = {}\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        next(f)  # Skip the first line (header)\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]  # The word\n",
    "            vector = np.asarray(values[1:], dtype='float32')  # The embedding vector\n",
    "            embeddings[word] = vector\n",
    "    print(f\"Loaded {len(embeddings)} word vectors.\")\n",
    "    return embeddings\n",
    "\n",
    "# Path to your FastText embedding file (e.g., cc.en.300.vec)\n",
    "fasttext_path = \"/projappl/project_2006600/fin_experiment/embeddings/crawl-300d-2M.vec\"\n",
    "embedding_dim = 300\n",
    "fasttext_embeddings = load_fasttext_embeddings(fasttext_path, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16c136b3-49db-4172-b2fc-f71bb41b4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300#100  # GloVe embedding dimension\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Initialize embedding matrix with random values\n",
    "embedding_matrix = np.random.uniform(-0.01, 0.01, (vocab_size, embedding_dim))\n",
    "\n",
    "# Fill the embedding matrix with GloVe embeddings\n",
    "for word, idx in vocab.token_to_idx.items():\n",
    "    if word in fasttext_embeddings:#glove_embeddings:\n",
    "        embedding_matrix[idx] = fasttext_embeddings[word]\n",
    "    elif word == \"<pad>\" or word == \"<unk>\":\n",
    "        embedding_matrix[idx] = np.zeros(embedding_dim)  # Padding token\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6774897f-42eb-4d6e-978e-fea63086520e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16358, 300])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2588d505-63bf-47d2-8aaa-f588bbd2e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "class NewsDatasetFixedLen(Dataset):\n",
    "    def __init__(self, texts, labels, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.values[idx]\n",
    "        tokenized = tokenize(text)[:self.max_len]\n",
    "        # tokenized += [0] * (self.max_len - len(tokenized))\n",
    "        text = torch.tensor([vocab.get(token) for token in tokenized])\n",
    "        label = torch.tensor(self.labels.values[idx], dtype=torch.float32)\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1eed0c7c-0786-44ea-a641-667f0aed1c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NewsDatasetFixedLen(X_train, y_train, 900)\n",
    "valid_dataset = NewsDatasetFixedLen(X_valid, y_valid, 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "993aa14c-cf7c-42a6-9f8c-04044a8ac671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.4375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset) / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4d999231-b97d-4444-a518-891d5517b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(next(iter(valid_dataset)))\n",
    "# Collate function to pad sequences\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    padded_sequence = pad_sequence(texts, batch_first=True)\n",
    "    labels = torch.stack(labels)\n",
    "    return padded_sequence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d05fd525-620e-497e-9c1f-d66c623e6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the embedding layer\n",
    "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Load the pre-trained weights\n",
    "embedding_layer.weight = nn.Parameter(embedding_matrix)\n",
    "\n",
    "# Optionally freeze the embeddings\n",
    "embedding_layer.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af4123a3-e1d1-4652-b9ba-3e3e4a9dd6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_channels, kernel_sizes, **kwargs):\n",
    "        super(TextCNN, self).__init__(**kwargs)\n",
    "        # self.embedding = embedding_layer\n",
    "        # self.embedding.weight.requires_grad = True\n",
    "        self.constant_embedding = embedding_layer\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.append(nn.Conv1d(embedding_dim, c, k))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(c))\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        # self.dense = nn.Linear(sum(num_channels), 128)\n",
    "        self.decoder = nn.Linear(sum(num_channels), 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # emb. layer = batch size * seq len * emb.dim\n",
    "        embedded = self.constant_embedding(x)\n",
    "        # embedded = torch.cat((self.embedding(x), self.constant_embedding(x)), dim=2)\n",
    "        # print(embedded.shape)\n",
    "        embedded = torch.permute(embedded, (0, 2, 1))\n",
    "        # print(torch.squeeze(self.relu(self.pool(self.convs[0](embedded))), dim=-1).shape)\n",
    "        # encoding = torch.cat([torch.squeeze(self.relu(self.pool(conv(embedded))), dim=-1) for conv in self.convs], dim=1)\n",
    "        encoding = []\n",
    "        for conv, batch_norm in zip(self.convs, self.batch_norms):\n",
    "            pooled_out = self.relu(self.pool(batch_norm(conv(embedded))))\n",
    "            encoding.append(torch.squeeze(pooled_out, dim=-1))\n",
    "        encoding = torch.cat(encoding, dim=1)\n",
    "        output = self.decoder(encoding)\n",
    "        return torch.squeeze(output)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc5c2b7c-fab9-4870-9bda-98a269d2f78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB MIG 1g.5gb\n",
      "Memory Usage:\n",
      "Allocated: 0.6 GB\n",
      "Cached:    0.6 GB\n"
     ]
    }
   ],
   "source": [
    "# Setting device on GPU if available\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "79b3d78c-8b3d-4eba-8f0d-83fce38199f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (constant_embedding): Embedding(16358, 300)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(300, 32, kernel_size=(2,), stride=(1,))\n",
       "    (1): Conv1d(300, 64, kernel_size=(3,), stride=(1,))\n",
       "    (2): Conv1d(300, 128, kernel_size=(4,), stride=(1,))\n",
       "  )\n",
       "  (batch_norms): ModuleList(\n",
       "    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (decoder): Linear(in_features=224, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size, kernel_sizes, nums_channels = embedding_dim, [2, 3, 4], [32, 64, 128]\n",
    "net = TextCNN(len(vocab), embed_size, nums_channels, kernel_sizes)\n",
    "\n",
    "def init_weights(module):\n",
    "    if type(module) in (nn.Linear, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c75e316f-dfda-48bb-813d-26e673a11e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainArgs:\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    epochs: int\n",
    "\n",
    "cnn_args = TrainArgs(1e-3, 64, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ac39cd2f-9a1a-488c-b125-e2040462069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=cnn_args.batch_size, collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=cnn_args.batch_size, collate_fn=collate_fn)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41d03e51-e85c-44e3-b6a4-cbed672f2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(net.parameters(), lr=cnn_args.learning_rate, weight_decay=1e-6)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Reduce LR by 10x every 2 epochs\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, loss_fn, device, epochs):\n",
    "    model.to(device)\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for input_ids, labels in train_loader:\n",
    "            input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_ids)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss = evaluate_model(model, val_loader, loss_fn, device)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        scheduler.step(val_loss)\n",
    "        valid_losses.append(val_loss)\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Saved best model.\")\n",
    "\n",
    "def evaluate_model(model, val_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in val_loader:\n",
    "            input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "            logits = model(input_ids)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "            probs = torch.sigmoid(logits)\n",
    "            predictions = (probs > 0.5).float()\n",
    "            # Update correct predictions\n",
    "            running_corrects += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    acc = running_corrects / total_samples\n",
    "    print(f'Validation accuracy: {acc}')\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    return val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85304aab-3da2-45ec-b803-6525bc09fa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss: 0.7034\n",
      "Validation accuracy: 0.4271356783919598\n",
      "Validation Loss: 0.7108\n",
      "Saved best model.\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.11/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6748\n",
      "Validation accuracy: 0.4396984924623116\n",
      "Validation Loss: 0.7336\n",
      "Epoch 3/30\n",
      "Train Loss: 0.6605\n",
      "Validation accuracy: 0.4271356783919598\n",
      "Validation Loss: 0.7315\n",
      "Epoch 4/30\n",
      "Train Loss: 0.6460\n",
      "Validation accuracy: 0.43467336683417085\n",
      "Validation Loss: 0.7459\n",
      "Epoch 5/30\n",
      "Train Loss: 0.6300\n",
      "Validation accuracy: 0.4271356783919598\n",
      "Validation Loss: 0.7519\n",
      "Epoch 6/30\n",
      "Train Loss: 0.6122\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7532\n",
      "Epoch 7/30\n",
      "Train Loss: 0.5925\n",
      "Validation accuracy: 0.46733668341708545\n",
      "Validation Loss: 0.7489\n",
      "Epoch 8/30\n",
      "Train Loss: 0.5721\n",
      "Validation accuracy: 0.4798994974874372\n",
      "Validation Loss: 0.7471\n",
      "Epoch 9/30\n",
      "Train Loss: 0.5516\n",
      "Validation accuracy: 0.4648241206030151\n",
      "Validation Loss: 0.7686\n",
      "Epoch 10/30\n",
      "Train Loss: 0.5316\n",
      "Validation accuracy: 0.48743718592964824\n",
      "Validation Loss: 0.7625\n",
      "Epoch 11/30\n",
      "Train Loss: 0.5118\n",
      "Validation accuracy: 0.4824120603015075\n",
      "Validation Loss: 0.7779\n",
      "Epoch 12/30\n",
      "Train Loss: 0.4915\n",
      "Validation accuracy: 0.4748743718592965\n",
      "Validation Loss: 0.7954\n",
      "Epoch 13/30\n",
      "Train Loss: 0.4709\n",
      "Validation accuracy: 0.49748743718592964\n",
      "Validation Loss: 0.8023\n",
      "Epoch 14/30\n",
      "Train Loss: 0.4507\n",
      "Validation accuracy: 0.5100502512562815\n",
      "Validation Loss: 0.8110\n",
      "Epoch 15/30\n",
      "Train Loss: 0.4283\n",
      "Validation accuracy: 0.5201005025125628\n",
      "Validation Loss: 0.8173\n",
      "Epoch 16/30\n",
      "Train Loss: 0.4083\n",
      "Validation accuracy: 0.5175879396984925\n",
      "Validation Loss: 0.8271\n",
      "Epoch 17/30\n",
      "Train Loss: 0.3883\n",
      "Validation accuracy: 0.5201005025125628\n",
      "Validation Loss: 0.8380\n",
      "Epoch 18/30\n",
      "Train Loss: 0.3716\n",
      "Validation accuracy: 0.5251256281407035\n",
      "Validation Loss: 0.8317\n",
      "Epoch 19/30\n",
      "Train Loss: 0.3518\n",
      "Validation accuracy: 0.5402010050251256\n",
      "Validation Loss: 0.8390\n",
      "Epoch 20/30\n",
      "Train Loss: 0.3342\n",
      "Validation accuracy: 0.535175879396985\n",
      "Validation Loss: 0.8572\n",
      "Epoch 21/30\n",
      "Train Loss: 0.3166\n",
      "Validation accuracy: 0.5301507537688442\n",
      "Validation Loss: 0.8682\n",
      "Epoch 22/30\n",
      "Train Loss: 0.2992\n",
      "Validation accuracy: 0.5402010050251256\n",
      "Validation Loss: 0.8757\n",
      "Epoch 23/30\n",
      "Train Loss: 0.2831\n",
      "Validation accuracy: 0.5301507537688442\n",
      "Validation Loss: 0.8973\n",
      "Epoch 24/30\n",
      "Train Loss: 0.2663\n",
      "Validation accuracy: 0.535175879396985\n",
      "Validation Loss: 0.8937\n",
      "Epoch 25/30\n",
      "Train Loss: 0.2505\n",
      "Validation accuracy: 0.542713567839196\n",
      "Validation Loss: 0.9084\n",
      "Epoch 26/30\n",
      "Train Loss: 0.2372\n",
      "Validation accuracy: 0.542713567839196\n",
      "Validation Loss: 0.9287\n",
      "Epoch 27/30\n",
      "Train Loss: 0.2264\n",
      "Validation accuracy: 0.5326633165829145\n",
      "Validation Loss: 0.9692\n",
      "Epoch 28/30\n",
      "Train Loss: 0.2148\n",
      "Validation accuracy: 0.5326633165829145\n",
      "Validation Loss: 0.9893\n",
      "Epoch 29/30\n",
      "Train Loss: 0.2053\n",
      "Validation accuracy: 0.5276381909547738\n",
      "Validation Loss: 1.0228\n",
      "Epoch 30/30\n",
      "Train Loss: 0.1961\n",
      "Validation accuracy: 0.5201005025125628\n",
      "Validation Loss: 1.0658\n"
     ]
    }
   ],
   "source": [
    "train_model(net, train_dataloader, valid_dataloader, optimizer, loss_fn, device, cnn_args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a05cccd5-ef06-4271-b2f2-ff16bbc82300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockWithProjection(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(ResidualBlockWithProjection, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # Shortcut connection (projection using 1x1 convolution)\n",
    "        self.projection = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn_proj = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.projection(x)  # Project input to match output dimensions\n",
    "        identity = self.bn_proj(identity)\n",
    "\n",
    "        # Forward pass through convolutional layers\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # Add the shortcut connection\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d613bf20-05d6-4cce-bd6f-cf6d3daf5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualCNN(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "        self.constant_embedding = embedding_layer\n",
    "\n",
    "        # Initial convolutional layer\n",
    "        self.conv1 = nn.Conv1d(900, 64, kernel_size=3, stride=1, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Residual blocks\n",
    "        self.layer2 = ResidualBlockWithProjection(64, 128, stride=2)  # Change dimensions with projection\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.constant_embedding(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return torch.squeeze(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7cae6f8d-482d-4d0c-a485-3f2afe55b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResidualCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2e5f5a36-3c0c-4f51-b912-64f24bc08007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResidualCNN(\n",
       "  (constant_embedding): Embedding(16358, 300)\n",
       "  (conv1): Conv1d(900, 64, kernel_size=(3,), stride=(1,), padding=(3,), bias=False)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  (pool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer2): ResidualBlockWithProjection(\n",
       "    (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (projection): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
       "    (bn_proj): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e6150a34-7239-49b8-9b59-1ca41cf61afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.5703517587939698\n",
      "Validation Loss: 0.6833\n",
      "Saved best model.\n",
      "Epoch 2/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.5175879396984925\n",
      "Validation Loss: 0.6928\n",
      "Epoch 3/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.4472361809045226\n",
      "Validation Loss: 0.6998\n",
      "Epoch 4/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7005\n",
      "Epoch 5/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 6/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 7/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 8/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 9/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 10/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 11/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 12/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 13/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 14/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 15/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 16/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 17/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 18/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 19/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 20/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 21/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 22/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 23/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 24/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 25/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 26/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 27/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 28/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 29/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n",
      "Epoch 30/30\n",
      "Train Loss: 0.6950\n",
      "Validation accuracy: 0.44221105527638194\n",
      "Validation Loss: 0.7006\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, valid_dataloader, optimizer, loss_fn, device, cnn_args.epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
